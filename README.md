# Generative AI Support Assistant Backend

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-brightgreen.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Clean, production-style FastAPI backend** simulating a **Generative AI-powered customer support system**.

Demonstrates modern backend architecture patterns, AI service abstraction, structured logging, environment management and container-ready deployment â€” perfect for learning, portfolio showcase or as a foundation for real-world AI-integrated support platforms.

---

## âœ¨ Key Features

- REST API built with **FastAPI** (automatic OpenAPI/Swagger docs)
- Clean layered architecture (`routes` â†’ `services` â†’ `utils`)
- **Mocked AI engine** using keyword-based intent detection â€” **zero external dependencies**
- Service abstraction layer â€” **easy to swap mock â†’ real LLM** (OpenAI, Azure, Anthropic, Geminiâ€¦)
- Structured logging with correlation IDs
- Type-safe configuration via **Pydantic Settings**
- Multi-stage **Dockerfile** + **docker-compose** support
- Ready for future extensions: auth, persistence, conversation memory

---




## ğŸ“ Project Structure

```
ai-support-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py               # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py             # Typed environment settings
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ support.py        # /api/support endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ai_service.py     # Mock AI intent classifier
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py         # Logging configuration
â”œâ”€â”€ screenshots/              # Demo screenshots
â”‚   â”œâ”€â”€ swagger-ui.png
â”‚   â”œâ”€â”€ post-request.png
â”‚   â”œâ”€â”€ api-response.png
â”‚   â”œâ”€â”€ terminal-logs.png
â”‚   â””â”€â”€ docker-run.png
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---


---

## ğŸ›  Tech Stack

| Layer                | Technology               | Purpose                              |
|----------------------|--------------------------|--------------------------------------|
| Framework            | FastAPI                  | Async API, auto docs, validation     |
| Server               | Uvicorn                  | Production-grade ASGI server         |
| Validation/Settings  | Pydantic v2              | Type-safe models & config            |
| Logging              | Python logging           | Structured + correlation IDs         |
| Containerization     | Docker & Docker Compose  | Consistent dev â†’ prod environments   |
| Language             | Python 3.10+             | Modern syntax & performance          |

---

## ğŸš€ Quick Start (Local Development)

```bash
# 1. Clone the repository
git clone https://github.com/Biradarmahadev/Generative-AI-Support-Assistant-Backend.git
cd ai-support-backend

# 2. Create and activate virtual environment
python -m venv venv
source venv/bin/activate          # Linux / macOS
# venv\Scripts\activate           # Windows cmd
# source venv/Scripts/activate    # Windows Git Bash

# 3. Install dependencies
pip install -r requirements.txt

# 4. (optional) Copy example env file
cp .env.example .env

# 5. Start the server (auto-reload enabled)
uvicorn app.main:app --reload --port 8000

## âš™ï¸ Setup & Installation (Local)

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Biradarmahadev/Generative-AI-Support-Assistant-Backend.git
cd ai-support-backend
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/Scripts/activate   # Windows (Git Bash)
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Application

```bash
uvicorn app.main:app --reload --port 8000
```

---

## ğŸ” API Documentation

FastAPI automatically generates interactive API documentation.

Open in browser:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ“Œ API Usage

### POST `/api/support`

**Request Body**

```json
{
  "message": "I want a refund"
}
```

**Response**

```json
{
  "response": "Sure! Please share your order ID to process your refund."
}
```

---

## ğŸ¤– AI Service (Mocked)

The AI service uses **keyword-based intent detection** to simulate Generative AI behavior:

* Detects user intent (refund, delivery, login)
* Returns contextual responses
* Works fully offline

ğŸ” The mock service can be replaced with real LLM APIs without changing the API layer.

---

## ğŸ³ Docker Support

### Build Image

```bash
docker build -t ai-support-backend .
```

### Run Container

```bash
docker run -p 8000:8000 ai-support-backend
```

### Docker Compose

```bash
docker-compose up --build
```

---

## ğŸ“¸ Screenshots

The `screenshots/` directory contains:

* Swagger UI interface
* API request and response samples
* Terminal logs
* Docker container execution

These demonstrate the working backend and API responses.

---

## ğŸ” Environment Variables

Create a `.env` file using the template below:

```env
APP_NAME=AI Support Assistant Backend
ENV=development
```

---

## ğŸ“ˆ Future Enhancements

* Integrate real Generative AI APIs (OpenAI / Azure OpenAI)
* Add JWT-based authentication
* Persist chat history using a database
* Add CI/CD pipeline
* Implement async background tasks

---

## ğŸ‘¤ Author

**Mahadev**
Backend Developer | Python | FastAPI | AI-Integrated Systems

---

## ğŸ“„ License

This project is intended for learning, portfolio, and demonstration purposes.
